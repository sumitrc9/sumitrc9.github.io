<!DOCTYPE html>
<html>
<head>
	<title>Ethics of Autonomous Vehicles: Liability & Professional Responsibility</title>
</head>
<body>
	<h1>Liability & Professional Responsibility</h1>

	<p>
	As the driver is taken out of the driving equation, it becomes even more important to identify where liability falls when something goes wrong.  Upon introduction, autonomous vehicles are not going to be perfect driving machines. Regardless, autonomous vehicles need to be introduced in an ethical and socially acceptable way. To do so, professional responsibility must be upheld by members of all involved departments including designers, engineers, corporate leaders, and public policy makers in order to ensure ethical uses of this technology in society.    

	</p>

	<p>
		
	People who will design these vehicles will 


	Professionals are the most knowledgeable about their field. As such, they have the professional responsibility to make sure that ends achieved meet ethical standards [7]. On a micro-ethical level, this responsibility falls upon designers and engineers. Designers of autonomous vehicles have a say in the higher level decision making process and will need to abide by ethical principles when developing these processes.  In order to uphold ethical standards, both parties become ethically obligated to test their products
	</p>

	<p>
		
	Programmers must take it upon themselves to 

	Engineers must verify that the designer’s decisions are ethically sound when implementing them into the self-driving car [8].

	

	Programmers will need to minimize algorithmic bias. 

		
	While developing autonomous vehicles, it must be paramount to ensure that there is minimal algorithmic bias in order to uphold ethical standards. Oftentimes, the moral decision making algorithms of the vehicle will be reflective of the ethical ideologies of the programmer. 


	Autonomous vehicles make the majority of their decisions using computer vision and other in-built algorithms. However, many of these algorithms are susceptible to a form of algorithmic bias. One instance of this is evident in the accident regarding one of Uber’s prototypes for an autonomous vehicle. The automobile was unable to detect a pedestrian in the road causing an unfortunate accident. One of the causes for this accident can be linked towards representation bias in the algorithm where the dataset was not adequate with respect towards all possible scenarios the autonomous vehicles may face [1].  In machine learning, most algorithmic biases originate from the quality of the dataset [2]. As of right now, most self-driving cars are likely to be trained within specific cities or areas [3]. Since the vehicles are being trained in a localized environment, they are likely to have learned to follow the norms of the region they were trained and tested in. This can lead toward biased scenarios when the vehicle is used in  different contexts. Data that is centered around one city or area will be biased since the dataset was not comprehensive of all of the environments the car could be in. 

	In order to ensure that autonomous vehicles can function to the best of their ability, algorithmic bias will need to be mitigated. Fair algorithms will need to give similar predictions for similar individuals [1]. One possible method for reducing bias is by using better data collection practices and more comprehensive testing scenarios [1]. As aforementioned, many of the current datasets do not encompass the scope they need to. For example, many computer vision algorithms struggle to identify people of different ethnicities because the machine learning models were not exposed to comprehensive datasets. This type of bias can be minimized by ensuring that images used in these datasets are property labeled alongside other different verification strategies [2]. Currently one of machine learning’s shortcoming is that strictly defined labels make it difficult to properly evaluate abstract principles such as fairness and discrimination [4]. Although this is a problem that cannot be directly addressed in current AI research, as the field evolves, a possible way to eliminate bias may come from more dynamic labelling of data. On a more philosophical note, a common ideology is that fair algorithms will abide by the principles of egalitarianism since it can provide a sense of deontic justice [4]. When designing ethical algorithms, bais can arise from the nature of the people who design them and reflect their own personal ethics [3]. A solution to this type of bias might be to include more diversity of thought in current autonomous vehicle companies to ensure that varying ethical principles are contemplated and collectively decided upon when being applied to an autonomous vehicle. 

	The ideal self-driving will minimize and algorithmic biases and prioritize the safety of all actors involved. To accomplish this, it becomes the professional responsibility of the programmers and designers to ensure that proper ethical principles are applied when developing the algorithms that will some day revolutionize transportation.




	</p>

	<p>
	
	Additional liability will fall on corporate leaders 

	On the other hand, the macro-ethical responsibilities of autonomous vehicles fall primarily onto corporate leaders and public policy makers. With respect to self-driving cars, the primary macro-ethical issue becomes product liability. By removing a human driver from the liability equation, it becomes difficult to pinpoint who is responsible in the case of a malfunction. Liability can fall anywhere among the company which produced the technology, the manufacturer of the vehicle, the engineers, or the user [5]. Occasionally, companies transfer all liability to the consumer by making them sign a terms and conditions document. Nonetheless, the principles of professional responsibility may suggest that this is not ethically sound. 

	Fatal premise must be taken into account,
	</p>

	<p>
	
	Public policy makers will need to take it upon themselves to 

	Public policy makers need to be able to put into place policy regarding autonomous vehicles that delegates liability as dictated by the distribution of professional responsibility.


	A more indirect stakeholder of self-driving cars are public-policy makers and city planners. Primarily, these people will be concerned with the need to modify infrastructure to support this technology. Policy makers will need to experiment and identify the best way to introduce autonomous vehicles to urban environments [6]. Another concern for policy makers will be the interactions between autonomous vehicles and pedestrians and cyclists. City planners will need to test several ways self-driving cars can be integrated without disrupting or endangering other members of society [6]. Additionally, autonomous vehicles mean that less space will need to be wasted on parking [6]. Reductions in space allocated for parking will alter how urban planners design their cities. Autonomous vehicles will also revolutionize how people commute and have many environmental benefits. As such is the case, policy makers need to become increasingly flexible as self-driving cars are assimilated into society. 
	

	</p>

	<p>
	The value of ethics is truly seen if and only if engineers, designers, and corporate leaders uphold their professional responsibility to abide by the fundamental ethical standards that have been set for them. 

	Autonomous vehicles will strongly affect all of the stakeholders involved. Nevertheless, it is up to these stakeholders to ensure that this new technology is integrated smoothly into our society, for the benefit of all of everyone involved. 

	A major issue regarding the introduction of autonomous vehicles is identifying who is at fault when the machine does not behave as expected. Uber has been one of the pioneers in research for self-driving vehicles. Nonetheless, in March 2017, this company was involved in a high speed crash with an autonomous vehicle [9]. When analyzing this accident, it is important to consider the various agents that were involved. Automation calls for a rewrite in political liability laws as anybody throughout the supply chain can be liable for a malfunctioning robot [10]. In a future involving autonomous vehicles, companies like Uber will need to become responsible for the infrastructure that they introduce. These liability concerns once again demonstrate the political nature of self-driving vehicles.
	</p>

	<p>
		
	References:

	[7] C. Whitbeck, “Responsibility and Creativity in Engineering,” Emerging Technologies and Ethical Issues in Engineering: Papers from a Workshop, 2004. [Online]. Available: https://www.nap.edu/read/11083/chapter/8. [Accessed: 13-Jun-2020].
	
	[8] J. Borenstien, J. Herkert, and K. Miller, “Self-Driving Cars: Ethical Responsibilities of Design Engineers,” IEEE Technology and Society Magazine Vol. 36, No. 2 , 17-Jun-2017. [Online]. Available: https://ieeexplore.ieee.org/abstract/document/7947308. [Accessed: 14-Jun-2020].

	[5] G. E. Marchant and R. A. Lindor, “The Coming Collision Between Autonomous Vehicles and the Liability System,” Santa Clara Law Review, 17-Dec-2012. [Online]. Available: https://digitalcommons.law.scu.edu/cgi/viewcontent.cgi?referer=https://scholar.google.com/&httpsredir=1&article=2731&context=lawreview. [Accessed: 13-Jun-2020].

	[6] E. Fraedrich, D. Heinrichs, F. J. Bahamonde-Birke, and R. Cyganski, “Autonomous driving, the built environment and policy implications,” Transportation Research Part A: Policy and Practice, 17-Mar-2018. [Online]. Available: https://www.sciencedirect.com/science/article/pii/S0965856417301696. [Accessed: 20-Jun-2020].

	[1] N. Mehrabi, F. Morstatter, N. Saxena, K. Lerman, and A. Galstyan, “A Survey on Bias and Fairness in Machine Learning,” University of Southern California Information Sciences Institute, 17-Sep-2019. [Online]. Available: https://arxiv.org/pdf/1908.09635.pdf. [Accessed: 18-Jul-2020].
	
	[2] T. Tommasi, N. Patricia, B. Caputo, and T. Tuytelaars, “A Deeper Look at Dataset Bias,” SpringerLink, 13-Sep-2017. [Online]. Available: https://link.springer.com/chapter/10.1007/978-3-319-58347-1_2. [Accessed: 18-Jul-2020].
	
	[3] D. Danks and A. J. London, “Algorithmic Bias in Autonomous Systems,” International Joint Conference on Artificial Intelligence, 19-Aug-2017. [Online]. Available: https://www.researchgate.net/profile/Alex_London/publication/318830422_Algorithmic_Bias_in_Autonomous_Systems/links/5a4bb017aca2729b7c893d1b/Algorithmic-Bias-in-Autonomous-Systems.pdf. [Accessed: 18-Jul-2020].
	
	[4] R. Binns, “Fairness in Machine Learning: Lessons from Political Philosophy,” Journal of Machine Learning Research , 02-Jan-2018. [Online]. Available: https://arxiv.org/pdf/1712.03586.pdf. [Accessed: 18-Jul-2020].

	[9] D. Bissell, “Automation interrupted: How autonomous vehicle accidents transform the material politics of automation,” Political Geography, 19-May-2018. [Online]. Available: https://www.sciencedirect.com/science/article/pii/S0962629817303943. [Accessed: 06-Jun-2020].

	[10] P. Lin, K. Abney, and G. Beckey, “Robot ethics: Mapping the issues for a mechanized world,” Digital Commons @ Cal Poly, 2011. [Online]. Available: https://digitalcommons.calpoly.edu/cgi/viewcontent.cgi?article=1020&context=phil_fac. [Accessed: 06-Jun-2020].


	</p>


</body>
</html>